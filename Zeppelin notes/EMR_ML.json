{"paragraphs":[{"text":"%pyspark\n# Prepare data from s3 bucket\nfrom pyspark.sql import SQLContext\nfrom pyspark import SparkContext\nsqlContext = SQLContext(sc)\n\ntrain = sqlContext.read.load(\"s3://<your-S3-path>.csv\", format='com.databricks.spark.csv', header='true', \n    delimiter=',', inferSchema='true')\n","user":"anonymous","dateUpdated":"2019-02-24T09:27:52+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1551000472020_953155495","id":"20190213-082427_1614654583","dateCreated":"2019-02-24T09:27:52+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:816"},{"text":"%pyspark\n# Split data as training & testing data\ntrain_df,test_df=train.randomSplit([0.7,0.3],seed=123)\ntrain_df.cache()\ntest_df.cache()","user":"anonymous","dateUpdated":"2019-02-24T09:27:52+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"DataFrame[loan: string, contact: string, month: string, dayofweek: string, duration: int, campaign: int, pdays: int, previous: int, poutcome: string, empvarrate: int, conspriceidx: double, consconfidx: double, euribor3m: double, nremployed: double, label: int, age: int, job: string, marital: string, education: string, default: string, housing: string]\n"}]},"apps":[],"jobName":"paragraph_1551000472026_309118069","id":"20190213-082531_1115510540","dateCreated":"2019-02-24T09:27:52+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:817"},{"text":"%pyspark\ntrain_df.show(5)","user":"anonymous","dateUpdated":"2019-02-24T09:27:52+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----+--------+-----+---------+--------+--------+-----+--------+-----------+----------+------------+-----------+---------+----------+-----+---+-----------+--------+-------------------+-------+-------+\n|loan| contact|month|dayofweek|duration|campaign|pdays|previous|   poutcome|empvarrate|conspriceidx|consconfidx|euribor3m|nremployed|label|age|        job| marital|          education|default|housing|\n+----+--------+-----+---------+--------+--------+-----+--------+-----------+----------+------------+-----------+---------+----------+-----+---+-----------+--------+-------------------+-------+-------+\n|  no|cellular|  apr|      fri|       0|       3|  999|       0|nonexistent|        -1|      93.075|      -47.1|    1.479|    5099.1|    0| 53|blue-collar|divorced|        high.school|     no|    yes|\n|  no|cellular|  apr|      fri|      17|       4|  999|       0|nonexistent|        -1|      93.075|      -47.1|    1.405|    5099.1|    0| 36| technician| married|professional.course|     no|    yes|\n|  no|cellular|  apr|      fri|      31|       3|  999|       1|    failure|        -1|      93.075|      -47.1|    1.405|    5099.1|    0| 38| technician|  single|  university.degree|     no|    yes|\n|  no|cellular|  apr|      fri|      33|       2|  999|       0|nonexistent|        -1|      93.075|      -47.1|    1.405|    5099.1|    0| 45|     admin.| married|        high.school|     no|    yes|\n|  no|cellular|  apr|      fri|      36|       1|  999|       0|nonexistent|        -1|      93.075|      -47.1|    1.405|    5099.1|    0| 35|   services| married|        high.school|     no|    yes|\n+----+--------+-----+---------+--------+--------+-----+--------+-----------+----------+------------+-----------+---------+----------+-----+---+-----------+--------+-------------------+-------+-------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1551000472026_-1404801489","id":"20190219-093709_1707285735","dateCreated":"2019-02-24T09:27:52+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:818"},{"text":"%pyspark\n# Create ML pipeline\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\nfrom pyspark.ml.classification import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier(labelCol=\"label\",featuresCol=\"features\",impurity=\"gini\",maxBins=14)\n\ncols = ['contact', 'loan', 'month', 'dayofweek' , 'poutcome' , 'job', 'marital' , 'education' , 'housing']\n\nindexers = [\n    StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c))\n    for c in cols\n]\n\nencoders = [\n    OneHotEncoder(\n        inputCol=indexer.getOutputCol(),\n        outputCol=\"{0}_encoded\".format(indexer.getOutputCol())) \n    for indexer in indexers\n]\n\nassembler = VectorAssembler(\n    inputCols=[encoder.getOutputCol() for encoder in encoders],\n    outputCol=\"features\"\n)\n\n\ndtpipeline = Pipeline(stages=indexers + encoders + [assembler] + [dt])\ndtpipelineModel = dtpipeline.fit(train_df)\n\n","user":"anonymous","dateUpdated":"2019-02-24T09:27:52+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1551000472027_-570810519","id":"20190219-101142_918292529","dateCreated":"2019-02-24T09:27:52+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:819"},{"text":"%pyspark\n#Build decision tree model\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\",labelCol=\"label\",metricName=\"areaUnderROC\")\npredictions=dtpipelineModel.transform(test_df)\n#predictions.show(2)\nauc=evaluator.evaluate(predictions)\nauc","user":"anonymous","dateUpdated":"2019-02-24T09:27:52+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"0.3658414908188737\n"}]},"apps":[],"jobName":"paragraph_1551000472027_-2076141894","id":"20190213-083028_768121653","dateCreated":"2019-02-24T09:27:52+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:820"},{"text":"%pyspark\n#Build random forest model\nfrom pyspark.ml.classification import RandomForestClassifier\nrf = RandomForestClassifier(labelCol=\"label\",featuresCol=\"features\",numTrees=2)\n#rfpipeline = Pipeline(stages=[indexers,encoder,assembler,rf])\nrfpipeline = Pipeline(stages=indexers + encoders + [assembler] + [rf])\nrfpipelineModel = rfpipeline.fit(train_df)\nrfpredictrd = rfpipelineModel.transform(test_df)\nauc=evaluator.evaluate(rfpredictrd)\nauc\n","user":"anonymous","dateUpdated":"2019-02-24T09:32:58+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"0.7721378095905692\n"}]},"apps":[],"jobName":"paragraph_1551000472028_2007949670","id":"20190213-083059_934179173","dateCreated":"2019-02-24T09:27:52+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:821"},{"text":"%pyspark\n#random forest & 2 fold Crossvalidation\nfrom pyspark.ml.tuning import CrossValidator,ParamGridBuilder\nparamGrid = ParamGridBuilder()\\\n    .addGrid(rf.impurity,[\"gini\",\"entropy\"])\\\n    .addGrid(rf.maxBins,[10,15,20])\\\n    .addGrid(rf.maxDepth,[5,10,15])\\\n    .addGrid(rf.numTrees,[10,20,30])\\\n    .build()\n    \nrfcv = CrossValidator(estimator=rf,evaluator=evaluator,estimatorParamMaps=paramGrid,numFolds=2)\nrfcv_pipeline = Pipeline(stages=indexers + encoders + [assembler] + [rfcv])\nrfcv_pipeline_Model = rfcv_pipeline.fit(train_df)\n#bestModel = rfcv_pipeline_Model.stages[3].bestModel\n#bestModel\npredictions=rfcv_pipeline_Model.transform(test_df)\n#predictions.show(2)\nauc=evaluator.evaluate(predictions)\nauc","user":"anonymous","dateUpdated":"2019-02-24T09:31:41+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1551000472029_228007240","id":"20190213-092626_494570329","dateCreated":"2019-02-24T09:27:52+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:822"}],"name":"EMR ML","id":"2E4PU92U5","noteParams":{},"noteForms":{},"angularObjects":{"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}
